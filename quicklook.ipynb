{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries related to querying links and downloading files from the web\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "from IPython.display import display, clear_output, Video\n",
    "import importlib\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import pipmag as pm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the pipmag module to make sure that the latest version is used\n",
    "importlib.reload(pm)\n",
    "print('Imported updated pipmag.py')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Generating the dataframe from SST quicklooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the years for which the La Palma Observatory has data at UiO\n",
    "obs_years = pm.get_obs_years()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observing dates for all the years\n",
    "obs_dates = pm.get_obs_dates(obs_years)\n",
    "obs_dates_list = pm.get_obs_dates_list(obs_dates)\n",
    "# print the first, last and total number of observing dates\n",
    "print(f'first entry: {obs_dates_list[0]}\\nlast entry : {obs_dates_list[-1]}\\ntotal observing dates: {len(obs_dates_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest file from the list of files in the data directory\n",
    "latest_all_media_links_file = pm.get_latest_file('data/all_media_links*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all_media_links.pkl exists then load the pickle file, otherwise get the links\n",
    "if latest_all_media_links_file is None:\n",
    "    video_links = pm.get_video_liks(obs_dates) # get the video links, one for each observing date\n",
    "    image_links = pm.get_image_links(obs_dates) # get the image links, one for each observing date\n",
    "    all_image_links = pm.get_all_links(image_links) # get all the image links, one for each image\n",
    "    all_video_links = pm.get_all_links(video_links) # get all the video links, one for each video\n",
    "    # print the number of video and image links and all the video and image links \n",
    "    print(f'number of video links: {len(all_video_links)}\\nnumber of image links: {len(all_image_links)}')\n",
    "    print(f'video links: {len(all_video_links)}\\nimage links: {len(all_image_links)}')\n",
    "    all_media_links = all_image_links + all_video_links # combine the image and video links\n",
    "    all_media_links = sorted(all_media_links) #sort the list of links\n",
    "    # print the total number of media links\n",
    "    print(f'total number of media links: {len(all_media_links)}')\n",
    "    # save all the media links as a pickle file\n",
    "    pm.save_pickle(all_media_links, 'data/'+ pm.add_timestamp('all_media_links.pkl'))\n",
    "else:\n",
    "    # load the latest pickle file\n",
    "    all_media_links = pm.load_pickle(latest_all_media_links_file )\n",
    "    print(f'total number of media links: {len(all_media_links)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the date and time from the links and find the links that do not have date and time and save them as a list\n",
    "date_time_from_all_media_links, date_time_not_found = pm.get_date_time_from_link_list(all_media_links)\n",
    "# remove all the links that do not have a date and time from all_media_links\n",
    "all_media_links_with_date_time = [link for link in all_media_links if link not in date_time_not_found]\n",
    "# print the number of links that contain date and time and the number of links that do not contain date and time\n",
    "print(f'number of links with date and time: {len(all_media_links_with_date_time)}\\nnumber of links without date and time: {len(date_time_not_found)}')\n",
    "invalid_dates = pm.get_invalid_dates(date_time_from_all_media_links)\n",
    "# remove the entries from date_time_from_all_media_links that are not in the correct format\n",
    "date_time_from_all_media_links = [date for date in date_time_from_all_media_links if date not in invalid_dates]\n",
    "# find the string pattern before the underscore in the invalid dates and search for the pattern in the links with date and time and save the links that contain the pattern in a list\n",
    "invalid_dates_pattern = [re.search(r'(.+?)_', date).group(1) for date in invalid_dates]\n",
    "# find the links that contain the pattern in invalid_dates_pattern and save them in a list\n",
    "invalid_dates_links = [link for link in all_media_links_with_date_time if any(pattern in link for pattern in invalid_dates_pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date and time to datetime format\n",
    "date_time_from_all_media_links_datetime = pm.convert_to_datetime(date_time_from_all_media_links)\n",
    "# get the unique date_time_from_all_media_links_datetime  values\n",
    "unique_date_time_from_all_media_links_datetime = list(set(date_time_from_all_media_links_datetime))\n",
    "# print the number of unique date_time_from_all_media_links_datetime values\n",
    "print(f'number of unique date_time_from_all_media_links_datetime values: {len(unique_date_time_from_all_media_links_datetime)}')\n",
    "# create a dataframe with the date_time_from_all_media_links_datetime as the index and the all_media_links as the column\n",
    "df = pd.DataFrame(all_media_links_with_date_time, index=date_time_from_all_media_links_datetime, columns=['links'])\n",
    "#print first, last and total number of entries in the dataframe\n",
    "print(f'first entry: {df.index[0]}\\nlast entry : {df.index[-1]}\\ntotal entries: {len(df.index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by the time index and combine the links into a list\n",
    "df = df.groupby(df.index).agg({'links': lambda x: list(x)})\n",
    "# print the first, last and total number of entries in the dataframe\n",
    "print(f'first entry: {df.index[0]}\\nlast entry : {df.index[-1]}\\ntotal entries: {len(df.index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column called 'obs_id' and set it equal to the row number of the dataframe\n",
    "# add the 'id' column\n",
    "df['obs_id'] = range(0, len(df))\n",
    "# set the index as 'obs_id' and add a column for the date and time\n",
    "df['date_time'] = df.index\n",
    "df = df.set_index('obs_id')\n",
    "# add a column for the number of links in each row\n",
    "df['num_links'] = df['links'].apply(lambda x: len(x))\n",
    "# add columns for the year, month and day to the dataframe\n",
    "df['year'] = df['date_time'].apply(lambda x: x.year)\n",
    "df['month'] = df['date_time'].apply(lambda x: x.month)\n",
    "df['day'] = df['date_time'].apply(lambda x: x.day)\n",
    "# add a column for the time of day\n",
    "df['time'] = df['date_time'].apply(lambda x: x.time())\n",
    "# add a column called 'target' and set it equal to None\n",
    "df['target'] = None\n",
    "df['comments'] = None\n",
    "df['polarimetry'] = None\n",
    "instrument_keywords={'CRISP': ['wb_6563','ha','Crisp','6173','8542','6563','crisp'],'CHROMIS':['Chromis','cak','4846'],'IRIS':['sji']}\n",
    "# apply the get_instrument_info function to the 'links' column of the dataframe and add the result to a new column called 'instruments'\n",
    "df['instruments'] = df['links'].apply(lambda x: pm.get_instrument_info(x, instrument_keywords))\n",
    "# apply the get_links_with_string function to the 'links' column of the dataframe with the strings 'mp4' and 'mov' and add the result to a new column called 'video_links'\n",
    "df['video_links'] = df['links'].apply(lambda x: pm.get_links_with_string(x, ['mp4','mov']))\n",
    "# apply the get_links_with_string function to the 'links' column of the dataframe with the strings 'jpg' and 'png' and add the result to a new column called 'image_links'\n",
    "df['image_links'] = df['links'].apply(lambda x: pm.get_links_with_string(x, ['jpg','png']))\n",
    "#pm.get_links_with_string(df.iloc[0]['links'], ['mp4','mov'])\n",
    "# make the columns date-time, year, month, day, time, instruments, target, video_links, image_links, links, num_links\n",
    "df = df[['date_time', 'year', 'month', 'day', 'time', 'instruments', 'target', 'comments','video_links', 'image_links', 'links', 'num_links','polarimetry']]\n",
    "# print a summary of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix duplicate times ## \n",
    "\n",
    "# Convert 'date_time' column to DateTime type\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "\n",
    "# Sort the DataFrame by 'date_time'\n",
    "df_ = df.sort_values('date_time')\n",
    "\n",
    "# Define threshold for time difference \n",
    "threshold = timedelta(seconds=60) \n",
    "\n",
    "# Group rows based on time proximity\n",
    "grouped_df = df_.groupby((df_['date_time'].diff() > threshold).cumsum()).agg({\\\n",
    "    'date_time': 'first', 'year': 'first', 'month': 'first', 'day': 'first', 'time': 'first', 'instruments': 'sum', \\\n",
    "        'target': 'first', 'comments': 'first', 'video_links': 'sum', 'image_links': 'sum', 'links': 'sum', \\\n",
    "            'num_links': 'sum', 'polarimetry': 'min'})\n",
    "\n",
    "# convert the 'date_time' column back \n",
    "grouped_df['date_time'] = grouped_df['date_time'].apply(lambda x: x.to_pydatetime())\n",
    "\n",
    "grouped_df.to_pickle('data/'+ pm.add_timestamp('la_palma_obs_data.pkl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚û°Ô∏è Start here : Load the existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest pickle file\n",
    "latest_updated_la_palma_obs_data_file = pm.get_latest_file('data/la_palma_obs_data_*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(latest_updated_la_palma_obs_data_file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a widget to display movies based on year, month, day and time\n",
    "# and to update the target, instrumnets and comments columns of the dataframe\n",
    "selector = pm.VideoSelector2(df, ['target', 'instruments', 'polarimetry', 'comments'])\n",
    "selector.create_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç ADS Search\n",
    "index = 36\n",
    "search = pm.ADS_Search(df)\n",
    "search.get_results(index, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the updated dataframe as a pickle file\n",
    "df.to_pickle('data/'+ pm.add_timestamp('la_palma_obs_data.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
