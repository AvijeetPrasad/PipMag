{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries related to querying links and downloading files from the web\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from IPython.display import display, clear_output, Video\n",
    "import importlib\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from pipmag import pipmag as pm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported updated pipmag.py\n"
     ]
    }
   ],
   "source": [
    "# reload the pipmag module to make sure that the latest version is used\n",
    "importlib.reload(pm)\n",
    "print('Imported updated pipmag.py')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚙️ Generating the dataframe from SST quicklooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the years for which the La Palma Observatory has data at UiO\n",
    "obs_years = pm.get_obs_years()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first entry: 2013-06-30\n",
      "last entry : 2023-05-16\n",
      "total observing dates: 122\n"
     ]
    }
   ],
   "source": [
    "# Get the observing dates for all the years\n",
    "obs_dates = pm.get_obs_dates(obs_years)\n",
    "obs_dates_list = pm.get_obs_dates_list(obs_dates)\n",
    "# print the first, last and total number of observing dates\n",
    "print(f'first entry: {obs_dates_list[0]}\\nlast entry : {obs_dates_list[-1]}\\ntotal observing dates: {len(obs_dates_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest file: ../data/all_media_links_20230215_192642.pkl\n"
     ]
    }
   ],
   "source": [
    "# get the latest file from the list of files in the data directory\n",
    "latest_all_media_links_file = pm.get_latest_file('../data/all_media_links*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ../data/all_media_links_20230215_192642.pkl successfully\n",
      "total number of media links: 6878\n"
     ]
    }
   ],
   "source": [
    "# check if all_media_links.pkl exists then load the pickle file, otherwise get the links\n",
    "if latest_all_media_links_file is None:\n",
    "    video_links = pm.get_video_liks(obs_dates) # get the video links, one for each observing date\n",
    "    image_links = pm.get_image_links(obs_dates) # get the image links, one for each observing date\n",
    "    all_image_links = pm.get_all_links(image_links) # get all the image links, one for each image\n",
    "    all_video_links = pm.get_all_links(video_links) # get all the video links, one for each video\n",
    "    # print the number of video and image links and all the video and image links \n",
    "    print(f'number of video links: {len(all_video_links)}\\nnumber of image links: {len(all_image_links)}')\n",
    "    print(f'video links: {len(all_video_links)}\\nimage links: {len(all_image_links)}')\n",
    "    all_media_links = all_image_links + all_video_links # combine the image and video links\n",
    "    all_media_links = sorted(all_media_links) #sort the list of links\n",
    "    # print the total number of media links\n",
    "    print(f'total number of media links: {len(all_media_links)}')\n",
    "    # save all the media links as a pickle file\n",
    "    pm.save_pickle(all_media_links, 'data/'+ pm.add_timestamp('all_media_links.pkl'))\n",
    "else:\n",
    "    # load the latest pickle file\n",
    "    all_media_links = pm.load_pickle(latest_all_media_links_file )\n",
    "    print(f'total number of media links: {len(all_media_links)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of links with date and time: 6817\n",
      "number of links without date and time: 61\n",
      "All dates in date_time_list are valid\n"
     ]
    }
   ],
   "source": [
    "# get the date and time from the links and find the links that do not have date and time and save them as a list\n",
    "date_time_from_all_media_links, date_time_not_found = pm.get_date_time_from_link_list(all_media_links)\n",
    "# remove all the links that do not have a date and time from all_media_links\n",
    "all_media_links_with_date_time = [link for link in all_media_links if link not in date_time_not_found]\n",
    "# print the number of links that contain date and time and the number of links that do not contain date and time\n",
    "print(f'number of links with date and time: {len(all_media_links_with_date_time)}\\nnumber of links without date and time: {len(date_time_not_found)}')\n",
    "invalid_dates = pm.get_invalid_dates(date_time_from_all_media_links)\n",
    "# remove the entries from date_time_from_all_media_links that are not in the correct format\n",
    "date_time_from_all_media_links = [date for date in date_time_from_all_media_links if date not in invalid_dates]\n",
    "# find the string pattern before the underscore in the invalid dates and search for the pattern in the links with date and time and save the links that contain the pattern in a list\n",
    "invalid_dates_pattern = [re.search(r'(.+?)_', date).group(1) for date in invalid_dates]\n",
    "# find the links that contain the pattern in invalid_dates_pattern and save them in a list\n",
    "invalid_dates_links = [link for link in all_media_links_with_date_time if any(pattern in link for pattern in invalid_dates_pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique date_time_from_all_media_links_datetime values: 748\n",
      "first entry: 2013-06-30 09:15:50\n",
      "last entry : 2022-09-08 08:40:11\n",
      "total entries: 6817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert the date and time to datetime format\n",
    "date_time_from_all_media_links_datetime = pm.convert_to_datetime(date_time_from_all_media_links)\n",
    "# get the unique date_time_from_all_media_links_datetime  values\n",
    "unique_date_time_from_all_media_links_datetime = list(set(date_time_from_all_media_links_datetime))\n",
    "# print the number of unique date_time_from_all_media_links_datetime values\n",
    "print(f'number of unique date_time_from_all_media_links_datetime values: {len(unique_date_time_from_all_media_links_datetime)}')\n",
    "# create a dataframe with the date_time_from_all_media_links_datetime as the index and the all_media_links as the column\n",
    "df = pd.DataFrame(all_media_links_with_date_time, index=date_time_from_all_media_links_datetime, columns=['links'])\n",
    "#print first, last and total number of entries in the dataframe\n",
    "print(f'first entry: {df.index[0]}\\nlast entry : {df.index[-1]}\\ntotal entries: {len(df.index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first entry: 2013-06-30 09:15:50\n",
      "last entry : 2022-09-17 14:34:13\n",
      "total entries: 748\n"
     ]
    }
   ],
   "source": [
    "# group the dataframe by the time index and combine the links into a list\n",
    "df = df.groupby(df.index).agg({'links': lambda x: list(x)})\n",
    "# print the first, last and total number of entries in the dataframe\n",
    "print(f'first entry: {df.index[0]}\\nlast entry : {df.index[-1]}\\ntotal entries: {len(df.index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 748 entries, 0 to 747\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   date_time    748 non-null    datetime64[ns]\n",
      " 1   year         748 non-null    int64         \n",
      " 2   month        748 non-null    int64         \n",
      " 3   day          748 non-null    int64         \n",
      " 4   time         748 non-null    object        \n",
      " 5   instruments  746 non-null    object        \n",
      " 6   target       0 non-null      object        \n",
      " 7   comments     0 non-null      object        \n",
      " 8   video_links  748 non-null    object        \n",
      " 9   image_links  748 non-null    object        \n",
      " 10  links        748 non-null    object        \n",
      " 11  num_links    748 non-null    int64         \n",
      " 12  polarimetry  0 non-null      object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(8)\n",
      "memory usage: 81.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# add a column called 'obs_id' and set it equal to the row number of the dataframe\n",
    "# add the 'id' column\n",
    "df['obs_id'] = range(0, len(df))\n",
    "# set the index as 'obs_id' and add a column for the date and time\n",
    "df['date_time'] = df.index\n",
    "df = df.set_index('obs_id')\n",
    "# add a column for the number of links in each row\n",
    "df['num_links'] = df['links'].apply(lambda x: len(x))\n",
    "# add columns for the year, month and day to the dataframe\n",
    "df['year'] = df['date_time'].apply(lambda x: x.year)\n",
    "df['month'] = df['date_time'].apply(lambda x: x.month)\n",
    "df['day'] = df['date_time'].apply(lambda x: x.day)\n",
    "# add a column for the time of day\n",
    "df['time'] = df['date_time'].apply(lambda x: x.time())\n",
    "# add a column called 'target' and set it equal to None\n",
    "df['target'] = None\n",
    "df['comments'] = None\n",
    "df['polarimetry'] = None\n",
    "instrument_keywords={'CRISP': ['wb_6563','ha','Crisp','6173','8542','6563','crisp'],'CHROMIS':['Chromis','cak','4846'],'IRIS':['sji']}\n",
    "# apply the get_instrument_info function to the 'links' column of the dataframe and add the result to a new column called 'instruments'\n",
    "df['instruments'] = df['links'].apply(lambda x: pm.get_instrument_info(x, instrument_keywords))\n",
    "# apply the get_links_with_string function to the 'links' column of the dataframe with the strings 'mp4' and 'mov' and add the result to a new column called 'video_links'\n",
    "df['video_links'] = df['links'].apply(lambda x: pm.get_links_with_string(x, ['mp4','mov']))\n",
    "# apply the get_links_with_string function to the 'links' column of the dataframe with the strings 'jpg' and 'png' and add the result to a new column called 'image_links'\n",
    "df['image_links'] = df['links'].apply(lambda x: pm.get_links_with_string(x, ['jpg','png']))\n",
    "#pm.get_links_with_string(df.iloc[0]['links'], ['mp4','mov'])\n",
    "# make the columns date-time, year, month, day, time, instruments, target, video_links, image_links, links, num_links\n",
    "df = df[['date_time', 'year', 'month', 'day', 'time', 'instruments', 'target', 'comments','video_links', 'image_links', 'links', 'num_links','polarimetry']]\n",
    "# print a summary of the dataframe\n",
    "df.info()\n",
    "# save the dataframe as a pickle file\n",
    "df.to_pickle('../data/'+ pm.add_timestamp('la_palma_obs_data.pkl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ➡️ Start here : Load the existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest file: ../data/la_palma_obs_data_20230706_092445.pkl\n"
     ]
    }
   ],
   "source": [
    "# get the latest pickle file\n",
    "latest_updated_la_palma_obs_data_file = pm.get_latest_file('../data/la_palma_obs_data_*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 748 entries, 0 to 747\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   date_time    748 non-null    datetime64[ns]\n",
      " 1   year         748 non-null    int64         \n",
      " 2   month        748 non-null    int64         \n",
      " 3   day          748 non-null    int64         \n",
      " 4   time         748 non-null    object        \n",
      " 5   instruments  746 non-null    object        \n",
      " 6   target       0 non-null      object        \n",
      " 7   comments     0 non-null      object        \n",
      " 8   video_links  748 non-null    object        \n",
      " 9   image_links  748 non-null    object        \n",
      " 10  links        748 non-null    object        \n",
      " 11  num_links    748 non-null    int64         \n",
      " 12  polarimetry  0 non-null      object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(8)\n",
      "memory usage: 81.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(latest_updated_la_palma_obs_data_file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab90777149b4edf8295a90629b5f16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Year:', options=(2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022), value=2013…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae260d61e883425a9d519106f5b92550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Month:', options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb57405ec36406d993bd40b13db94b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Day:', options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef75580b1b441efbd297ab7af4b16fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Time:', options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e712236fead4f729cea2362c3a40f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Links:', options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf322621638142d89fdb7e04ed1774f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1cfc701cbe47f0afdd605d9e22c187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eab16a22cb14c85b52a8384448c2e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='target:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0195b64e3b4d7aafc00d8db8749716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='instruments:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e202bc6c4c6640f78cdbfbc194fe2be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='polarimetry:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f505a384fa254fe8a4f00c31e8b653ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='comments:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b58dc9057a1427b8e55cc320b65cd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Update', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a widget to display movies based on year, month, day and time\n",
    "# and to update the target, instrumnets and comments columns of the dataframe\n",
    "selector = pm.VideoSelector2(df, ['target', 'instruments', 'polarimetry', 'comments'])\n",
    "selector.create_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>td { text-align: left; } th { text-align: center; }</style><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>#</th>\n",
       "      <th>Title</th>\n",
       "      <th>First author</th>\n",
       "      <th>Bibcode</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>On the dynamics of spicules and mass flows in the solar atmosphere</td>\n",
       "      <td>Bose, Souvik</td>\n",
       "      <td>2021arXiv211010656B</td>\n",
       "      <td><a href=\"https://ui.adsabs.harvard.edu/abs/2021arXiv211010656B\" target=\"_blank\">https://ui.adsabs.harvard.edu/abs/2021arXiv211010656B</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Evidence of the multi-thermal nature of spicular downflows. Impact on solar atmospheric heating</td>\n",
       "      <td>Bose, Souvik</td>\n",
       "      <td>2021A&A...654A..51B</td>\n",
       "      <td><a href=\"https://ui.adsabs.harvard.edu/abs/2021A&A...654A..51B\" target=\"_blank\">https://ui.adsabs.harvard.edu/abs/2021A&A...654A..51B</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Spicules and downflows in the solar chromosphere</td>\n",
       "      <td>Bose, Souvik</td>\n",
       "      <td>2021A&A...647A.147B</td>\n",
       "      <td><a href=\"https://ui.adsabs.harvard.edu/abs/2021A&A...647A.147B\" target=\"_blank\">https://ui.adsabs.harvard.edu/abs/2021A&A...647A.147B</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Analysis of Pseudo-Lyapunov Exponents of Solar Convection Using State-of-the-Art Observations</td>\n",
       "      <td>Viavattene, Giorgio</td>\n",
       "      <td>2021Entrp..23..413V</td>\n",
       "      <td><a href=\"https://ui.adsabs.harvard.edu/abs/2021Entrp..23..413V\" target=\"_blank\">https://ui.adsabs.harvard.edu/abs/2021Entrp..23..413V</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Characterization and formation of on-disk spicules in the Ca II K and Mg II k spectral lines</td>\n",
       "      <td>Bose, Souvik</td>\n",
       "      <td>2019A&A...631L...5B</td>\n",
       "      <td><a href=\"https://ui.adsabs.harvard.edu/abs/2019A&A...631L...5B\" target=\"_blank\">https://ui.adsabs.harvard.edu/abs/2019A&A...631L...5B</a></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🔍 ADS Search\n",
    "index = 36\n",
    "search = pm.ADS_Search(df)\n",
    "search.get_results(index, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the updated dataframe as a pickle file\n",
    "df.to_pickle('data/'+ pm.add_timestamp('la_palma_obs_data.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipmag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba2b68964390c77ef2e04277debd5475c8565a11fab30e531aaf9c5e1dfcc05e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
